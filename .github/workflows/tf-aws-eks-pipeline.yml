# Author:  Joe Harrison
# This is a GitHub Actions workflow that uses Terraform to deploy an AWS EKS cluster. 
# It will generate a main.tf file based on user input, in the root of the repository and then apply the Terraform configuration to create the EKS cluster. 
# If the Terraform apply fails, it will initiate a cleanup by destroying the resources created. The main.tf file and terraform state is then uploaded to an S3 bucket for future reference.

# Name of the workflow
name: AWS EKS CD

# Define environment variables
env:
  # AWS Access Key
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  # AWS Secret Key
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }}

# Define the events that trigger the workflow
on:
  # Trigger the workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      cluster_name:
        description: 'Enter a name for the cluster'
        required: true   
      vpc_id:
        description: 'Enter the VPC id i.e. vpc-00000000000000001'
        required: true        
      service_cidr:
        description: 'Enter the internal EKS service cidr to use within the cluster i.e. 10.200.0.0/16'
        required: true          
      vpc_subnet_ids:
        description: 'Enter 3 private subnets ids, comma seperated i.e. "subnet-00000000000000001,subnet-00000000000000002,subnet-00000000000000003"'
        required: true   
      vpc_public_subnet_id:
        description: 'Enter the public subnet id to deploy the jumpbox in i.e. "subnet-00000000000000001"'
        required: true         
      capacity_type:
        description: 'Select the deployment type'
        required: true
        type: choice
        options:
        - 'SPOT'
        - 'ON_DEMAND'
      client_tag:
        description: 'Enter the value to be used in the client tag (all lowercase) i.e. "client1" or "shared"'
        required: true    
      product_tag:
        description: 'Enter the value to be used in the product tag (all lowercase) i.e. "client1" or "shared"'
        required: true          
      environment_tag:
        description: 'Enter the value to be used in the env tag (all lowercase) i.e. "prod" or "dev"'
        required: true            

# Define permissions for this workflow
permissions:
  contents: read

# Define jobs in this workflow  
jobs:
  # Define a job for main.tf file actions
  generate-main-tf:
    name: 'Terraform EKS main.tf Generation'
    runs-on: [self-hosted, devops]
    environment: production

    steps:
      # Checkout the repository to the GitHub Actions runner 
      - name: Checkout
        uses: actions/checkout@v4   

      # If main.tf does not exist, we generate a new one using user input
      - name: Check if main.tf exists
        run: |
          if [ -f "main.tf" ]; then
            echo "main.tf already exists, skipping file generation."
            echo "file_exists=true" >> $GITHUB_ENV      
          else
            echo "main.tf does not exist, continuing with file generation."
            echo "file_exists=false" >> $GITHUB_ENV
          fi
        id: check-main-tf
      
      - name: Generate main.tf with user input
        if: env.file_exists == 'false'
        run: |
          DNS_IP=$(echo "${{ github.event.inputs.service_cidr }}" | python3 -c 'import ipaddress, sys; cidr = ipaddress.ip_network(sys.stdin.read().strip()); print(list(cidr.hosts())[9])')
          cat > main.tf << EOF
          # Define the required version of Terraform and the required AWS provider version
          terraform {
            required_version = ">= 1.5.0"

            backend "s3" {}
            
            required_providers {
              aws = {
                source  = "hashicorp/aws"
                version = "~> 5.0"
              }
              
            }
            
          }

          # Configure the AWS Provider
          provider "aws" {
            region = "eu-west-2"
          }

          # Define the module source and its location                    
          module "eks_cluster" {
            source = "./modules/aws-eks-cluster"          

            name                 = "<cluster_name>"
            eks_version          = "1.29"
            service_ipv4_cidr    = "<service_cidr>"
            core_dns_ip          = "${DNS_IP}"
            subnet_ids           = ["<vpc_subnet_id_1>", "<vpc_subnet_id_2>", "<vpc_subnet_id_3>"]
            public_subnet_id     = "<vpc_public_subnet_id>"
            vpc_id               = "<vpc_id>"          
            aws_access           = "<aws_access>"
            aws_secret           = "<aws_secret>"            

            addons = [
              {
                name    = "kube-proxy"
              },
              {
                name    = "vpc-cni"
              },
              {
                name    = "coredns"
              },
              {
                name    = "aws-ebs-csi-driver"
              }
              ,
              {
                name    = "aws-efs-csi-driver"
              }              
            ]          
            
            # Configuration for the first node pool
            node_pools = [
              {
                capacity_type = "<capacity_type>"
                node_group_name = "<cluster_name>-ng-<capacity_type_lowercase>"
                subnet_ids      = ["<vpc_subnet_id_1>", "<vpc_subnet_id_2>", "<vpc_subnet_id_3>"]
                tags = {
                    "environment"                                         = "<environment_tag>"
                    "client"                                              = "<client_tag>"
                    "product_tag"                                         = "<product_tag>"
                }
                desired_size = 3
                max_size     = 3
                min_size     = 1
                instance_types = ["m5a.2xlarge"]
            
                labels = {
                    "lifecycle" = "<capacity_type_lowercase>"
                    "managedby" = "terraform"
                }
                taint = []
              },
            ]          
            
            # Additional tagging for the EKS cluster.
            client_tag           = "<client_tag>"
            product_tag          = "<product_tag>"
            environment_tag         = "<environment_tag>"
          }          

          # Outputs from this configuration that will be displayed when Terraform is applied.
          output "eks_cluster_name" {
            value = module.eks_cluster.eks_cluster_name
          }          

          output "eks_cluster_endpoint" {
            value = module.eks_cluster.eks_cluster_endpoint
          }          

          output "eks_cluster_arn" {
            value = module.eks_cluster.eks_cluster_arn
          }          

          output "eks_cluster_version" {
            value = module.eks_cluster.eks_cluster_version
          }          

          output "eks_worker_nodes_security_group_id" {
            value = module.eks_cluster.eks_worker_nodes_security_group_id
          }          

          output "eks_cluster_security_group_id" {
            value = module.eks_cluster.eks_cluster_security_group_id
          }          

          output "eks_cluster_kms_key_arn" {
            value = module.eks_cluster.eks_cluster_kms_key_arn
          }
          
          output "encrypted_password_data" {
            value = module.eks_cluster.encrypted_password_data
            sensitive = true
          }
          
          EOF

          # Replace the placeholders with the actual input values
          sed -i "s|<cluster_name>|${{ github.event.inputs.cluster_name }}|g" main.tf
          sed -i "s|<vpc_id>|${{ github.event.inputs.vpc_id }}|g" main.tf
          sed -i "s|<service_cidr>|${{ github.event.inputs.service_cidr }}|g" main.tf

          IFS=',' read -ra VPC_SUBNET_IDS <<< "${{ github.event.inputs.vpc_subnet_ids }}"
          sed -i "s|<vpc_subnet_id_1>|${VPC_SUBNET_IDS[0]}|g" main.tf
          sed -i "s|<vpc_subnet_id_2>|${VPC_SUBNET_IDS[1]}|g" main.tf
          sed -i "s|<vpc_subnet_id_3>|${VPC_SUBNET_IDS[2]}|g" main.tf

          sed -i "s|<vpc_public_subnet_id>|${{ github.event.inputs.vpc_public_subnet_id }}|g" main.tf
          
          sed -i "s|<capacity_type>|${{ github.event.inputs.capacity_type }}|g" main.tf
          CAPACITY_LOWER=$(echo "${{ github.event.inputs.capacity_type }}" | tr 'A-Z' 'a-z')
          sed -i "s|<capacity_type_lowercase>|${CAPACITY_LOWER}|g" main.tf
          
          sed -i "s|<client_tag>|${{ github.event.inputs.client_tag }}|g" main.tf
          sed -i "s|<product_tag>|${{ github.event.inputs.product_tag }}|g" main.tf
          sed -i "s|<environment_tag>|${{ github.event.inputs.environment_tag }}|g" main.tf
          sed -i "s|<aws_access>|${{ env.AWS_ACCESS_KEY_ID }}|g" main.tf
          sed -i "s|<aws_secret>|${{ env.AWS_SECRET_ACCESS_KEY }}|g" main.tf          
           
          # Print the generated main.tf
          cat main.tf

      # If a new main.tf file was created, commit and push it to the repository
      - name: Commit and push main.tf
        if: env.file_exists == 'false'
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git add main.tf
          git commit -m "Add generated main.tf"
          git push
  
  # Define a job for Terraform actions          
  terraform-aws-eks-pipeline:
    name: 'Terraform AWS EKS Pipeline'
    needs: generate-main-tf
    runs-on: [self-hosted, devops]
    environment: production

    steps:
      # Checkout the repository to the GitHub Actions runner 
      - name: Checkout
        uses: actions/checkout@v4

      # Fetch the latest commit  
      - name: Fetch the latest commit
        run: |
          git fetch origin +refs/heads/*:refs/remotes/origin/* --depth=1
          LATEST_COMMIT=$(git rev-parse origin/${GITHUB_REF##*/})
          git checkout $LATEST_COMMIT          
        
      # Setup Node.js environment with a specific version
      - name: Node Setup
        uses: actions/setup-node@v3
        with:
          node-version: '20'      
      
      # Set up AWS CLI
      - name: Set up AWS CLI
        uses: aws-actions/configure-aws-credentials@v3
        with:
          aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
          aws-region: eu-west-2     
      
      # Setup Terraform CLI on the runner
      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2

      # Get Cluster Name
      - name: Get Cluster Name
        run: |
          echo "cluster_name=$(grep 'name\s*=' ./main.tf | awk -F"=" 'NR==1 {print $2}' | xargs)" >> $GITHUB_ENV
      
      # Initialise your Terraform working directory 
      - name: Terraform Init S3    
        run: |
          terraform init -backend-config="bucket=global-gh-tf-state" \
                        -backend-config="key=terraform-state-files/${{ env.cluster_name }}-tf-state/terraform.tfstate" \
                        -backend-config="encrypt=true" \
                        -backend-config="kms_key_id=arn:aws:kms:eu-west-2:accountnumberhere:key/key-id-here" \
                        -backend-config="region=eu-west-2" \
                        -backend-config="access_key=${{ env.AWS_ACCESS_KEY_ID }}" \
                        -backend-config="secret_key=${{ env.AWS_SECRET_ACCESS_KEY }}"

      # Generate an execution plan for Terraform
      - name: Terraform Plan
        run: terraform plan
      
        # Apply the changes required to reach the desired state of the configuration
      - name: Terraform Apply
        id: apply    
        continue-on-error: true
        run: terraform apply -auto-approve

      # Check if Terraform Apply failed and set an output variable
      - name: Check Terraform Apply Outcome
        id: check
        run: echo "apply_failed=${{ steps.apply.outcome == 'failure' }}" >> $GITHUB_ENV      
        
      # Destroy if Terraform Apply failed
      - name: Terraform Destroy
        if: env.apply_failed == 'true'
        id: failure-handler
        run: |
          echo "Terraform Apply failed. Initiating cleanup..."
          terraform destroy -auto-approve
          echo "cleanup_done=true" >> $GITHUB_ENV     

      # Upload the main.tf to s3
      - name: S3 Upload
        if: env.apply_failed != 'true'
        run:  |        
          aws s3 cp main.tf s3://global-gh-tf-state/terraform-state-files/${{ env.cluster_name }}-tf-state/main.tf
          if aws s3api head-object --bucket "global-gh-tf-state" --key "terraform-state-files/${{ env.cluster_name }}-tf-state/private_key.pem" 2>/dev/null; then
            echo "File already exists in S3. Not overwriting."
          else 
            aws s3 cp ${{ github.workspace }}/modules/aws-eks-cluster/private_key.pem s3://global-gh-tf-state/terraform-state-files/${{ env.cluster_name }}-tf-state/private_key.pem 
          fi