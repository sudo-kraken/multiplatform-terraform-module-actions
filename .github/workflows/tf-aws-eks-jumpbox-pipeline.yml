# Author:  Joe Harrison
# This is a GitHub Actions workflow that uses Terraform to deploy an AWS EC2 Jumpbox, to connect to an existing AWS EKS cluster. 
# It will generate a main.tf file based on user input, in the root of the repository and then apply the Terraform configuration to create the EC2 instance. 
# If the Terraform apply fails, it will initiate a cleanup by destroying the resources created. The main.tf file and terraform state is then uploaded to an S3 bucket for future reference.

# Name of the workflow
name: AWS EKS Jumpbox CD

# Define environment variables
env:
  # AWS Access Key
  AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY }}
  # AWS Secret Key
  AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_KEY }}

# Define the events that trigger the workflow
on:
  # Trigger the workflow manually from the Actions tab
  workflow_dispatch:
    inputs:
      # These inputs are details for the EKS environment, deployment parameters, and tags
      cluster_name:
        description: 'Enter the existing cluster name to attach the jumpbox to'
        required: true   
      vpc_id:
        description: 'Enter the VPC id i.e. vpc-00000000000000001'
        required: true        
      vpc_public_subnet_id:
        description: 'Enter the public subnet id to deploy the jumpbox in i.e. "subnet-00000000000000001"'
        required: true          
      client_tag:
        description: 'Enter the value to be used in the client tag (all lowercase) i.e. "client1" or "shared"'
        required: true    
      product_tag:
        description: 'Enter the value to be used in the product tag (all lowercase) i.e. "product1" or "product2"'
        required: true          
      environment_tag:
        description: 'Enter the value to be used in the env tag (all lowercase) i.e. "prod" or "dev"'
        required: true         

# Define permissions for this workflow
permissions:
  contents: read

# Define jobs in this workflow  
jobs:
  # Define a job for main.tf file actions
  generate-main-tf:
    name: 'Terraform EKS Jumpbox main.tf Generation'
    runs-on: [self-hosted, devops]
    environment: production

    steps:
      # Checkout the repository to the GitHub Actions runner 
      - name: Checkout
        uses: actions/checkout@v4

      # If main.tf does not exist, we generate a new one using user input
      - name: Check if main.tf exists
        run: |
          if [ -f "main.tf" ]; then
            echo "main.tf already exists, skipping file generation."
            echo "file_exists=true" >> $GITHUB_ENV      
          else
            echo "main.tf does not exist, continuing with file generation."
            echo "file_exists=false" >> $GITHUB_ENV
          fi
        id: check-main-tf
      
      - name: Generate main.tf with user input
        if: env.file_exists == 'false'
        run: |
          cat > main.tf << EOF
          # Define the required version of Terraform and the required AWS provider version
          terraform {
            required_version = ">= 1.5.0"

            backend "s3" {}
            
            required_providers {
              aws = {
                source  = "hashicorp/aws"
                version = "~> 5.0"
              }
              
            }
            
          }

          # Configure the AWS Provider          
          provider "aws" {
            region = "eu-west-2"
          }
          
          module "new_vpc" {
            source = "./modules/aws-ec2-jumpbox"
          
            name = "<cluster_name>"
            vpc_id = "<vpc_id>"
            public_subnet_id = "<vpc_public_subnet_id>"
            client_tag = "<client_tag>"
            product_tag = "<product_tag>"
            environment_tag = "<environment_tag>"
            aws_access = "<aws_access>"
            aws_secret = "<aws_secret>"
            
          }

          output "encrypted_password_data" {
            value = module.new_vpc.encrypted_password_data
            sensitive = true
          }

          EOF

          # Replace the placeholders with the actual input values
          sed -i "s|<cluster_name>|${{ github.event.inputs.cluster_name }}|g" main.tf
          sed -i "s|<vpc_id>|${{ github.event.inputs.vpc_id }}|g" main.tf
          sed -i "s|<vpc_public_subnet_id>|${{ github.event.inputs.vpc_public_subnet_id }}|g" main.tf
          sed -i "s|<client_tag>|${{ github.event.inputs.client_tag }}|g" main.tf
          sed -i "s|<product_tag>|${{ github.event.inputs.product_tag }}|g" main.tf
          sed -i "s|<environment_tag>|${{ github.event.inputs.environment_tag }}|g" main.tf
          sed -i "s|<aws_access>|${{ env.AWS_ACCESS_KEY_ID }}|g" main.tf
          sed -i "s|<aws_secret>|${{ env.AWS_SECRET_ACCESS_KEY }}|g" main.tf

          # Print the generated main.tf
          cat main.tf

      # If a new main.tf file was created, commit and push it to the repository
      - name: Commit and push main.tf
        if: env.file_exists == 'false'
        run: |
          git config --global user.name "GitHub Actions"
          git config --global user.email "github-actions@users.noreply.github.com"
          git add main.tf
          git commit -m "Add generated main.tf"
          git push

  # Define a job for Terraform actions          
  terraform-aws-jumpbox-pipeline:
    name: 'Terraform AWS Jumpbox Pipeline'
    needs: generate-main-tf
    runs-on: [self-hosted, devops]
    environment: production

    steps:          
    # Checkout the repository to the GitHub Actions runner 
    - name: Checkout
      uses: actions/checkout@v4

    # Fetch the latest commit  
    - name: Fetch the latest commit
      run: |
        git fetch origin +refs/heads/*:refs/remotes/origin/* --depth=1
        LATEST_COMMIT=$(git rev-parse origin/${GITHUB_REF##*/})
        git checkout $LATEST_COMMIT      
                
    # Setup Node.js environment with a specific version
    - name: Node Setup
      uses: actions/setup-node@v3
      with:
        node-version: '20'

    # Set up AWS CLI
    - name: Set up AWS CLI
      uses: aws-actions/configure-aws-credentials@v3
      with:
        aws-access-key-id: ${{ env.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ env.AWS_SECRET_ACCESS_KEY }}
        aws-region: eu-west-2     

    # Get Cluster Name
    - name: Get Cluster Name
      run: |
        echo "cluster_name=$(grep 'name\s*=' ./main.tf | awk -F"=" 'NR==1 {print $2}' | xargs)" >> $GITHUB_ENV         
    
    # Setup Terraform CLI on the runner
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v2
    
    # Initialise your Terraform working directory 
    - name: Terraform Init S3    
      run: |
        terraform init -backend-config="bucket=global-gh-tf-state" \
                       -backend-config="key=terraform-state-files/${{ env.cluster_name }}-jumpbox-tf-state/terraform.tfstate" \
                       -backend-config="encrypt=true" \
                       -backend-config="kms_key_id=arn:aws:kms:eu-west-2:accountnumberhere:key/key-id-here" \
                       -backend-config="region=eu-west-2" \
                       -backend-config="access_key=${{ env.AWS_ACCESS_KEY_ID }}" \
                       -backend-config="secret_key=${{ env.AWS_SECRET_ACCESS_KEY }}"

    # Generate an execution plan for Terraform
    - name: Terraform Plan
      run: terraform plan

      # Apply the changes required to reach the desired state of the configuration
    - name: Terraform Apply
      id: apply    
      continue-on-error: true
      run: terraform apply -auto-approve

    # Check if Terraform Apply failed and set an output variable
    - name: Check Terraform Apply Outcome
      id: check
      run: echo "apply_failed=${{ steps.apply.outcome == 'failure' }}" >> $GITHUB_ENV      
      
    # Destroy if Terraform Apply failed
    - name: Terraform Destroy
      if: env.apply_failed == 'true'
      id: failure-handler
      run: |
        echo "Terraform Apply failed. Initiating cleanup..."
        terraform destroy -auto-approve
        echo "cleanup_done=true" >> $GITHUB_ENV     
      
    # Upload the main.tf to s3
    - name: S3 Upload
      if: env.apply_failed != 'true'
      run:  |
        aws s3 cp main.tf s3://global-gh-tf-state/terraform-state-files/${{ env.cluster_name }}-jumpbox-tf-state/main.tf
        if aws s3api head-object --bucket "global-gh-tf-state" --key "terraform-state-files/${{ env.cluster_name }}-jumpbox-tf-state/private_key.pem" 2>/dev/null; then
          echo "File already exists in S3. Not overwriting."
        else 
          aws s3 cp ${{ github.workspace }}/modules/aws-ec2-jumpbox/private_key.pem s3://global-gh-tf-state/terraform-state-files/${{ env.cluster_name }}-jumpbox-tf-state/private_key.pem 
        fi